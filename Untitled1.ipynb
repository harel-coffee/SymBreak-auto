{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451185f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200_density' '200_grad' '1000_density']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cupy as cp\n",
    "from cupyx.scipy import ndimage\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# functions\n",
    "def generate_window(seed):\n",
    "    np.random.seed(seed)\n",
    "    random_pattern = np.random.rand(pattern_dim, pattern_dim)\n",
    "    binary_pattern = np.where(random_pattern < p, 1, 0)\n",
    "\n",
    "    org_locs = np.argwhere(binary_pattern == 1)\n",
    "\n",
    "    org_locs_scaled = org_locs*200+pad\n",
    "    pattern_dim_scaled = pattern_dim*200+2*pad\n",
    "    \n",
    "    centroids = []\n",
    "    im = np.zeros((pattern_dim_scaled, pattern_dim_scaled))\n",
    "\n",
    "    for y, x in org_locs_scaled:\n",
    "        im[y:y+150,x:x+150] = 255\n",
    "        centroids.append((y+75, x+75))\n",
    "    \n",
    "    return im, centroids\n",
    "\n",
    "def get_image(seed):\n",
    "    im, centroids = generate_window(seed)\n",
    "    while not len(centroids) > 2:\n",
    "        im, centroids = generate_window(seed)\n",
    "    return im, centroids\n",
    "\n",
    "def extract_features(image, sigma, centroids):\n",
    "\n",
    "    im_blur = ndimage.gaussian_filter(cp.array(image), sigma=sigma, mode='constant',cval=0)\n",
    "    im_blur_norm=im_blur*sigma*cp.sqrt(np.pi)\n",
    "\n",
    "    im_sx = ndimage.sobel(im_blur_norm, axis=1, mode='reflect')\n",
    "    im_sy = ndimage.sobel(im_blur_norm, axis=0, mode='reflect')\n",
    "    im_sobel=np.hypot(im_sx, im_sy)\n",
    "\n",
    "    feats = []\n",
    "   \n",
    "    for centroid in centroids:\n",
    "        x, y = centroid[0], centroid[1]\n",
    "        density = cp.mean(im_blur_norm[x-75: x+75, y-75: y+75])\n",
    "        grad = cp.mean(im_sobel[x-75: x+75, y-75: y+75])\n",
    "        feats.append([density.get(), grad.get()])\n",
    "\n",
    "    cp._default_memory_pool.free_all_blocks()\n",
    "\n",
    "    feats = np.array(feats)\n",
    "    return feats\n",
    "\n",
    "def simulate(image, centers, weights):\n",
    "    test_img = image.copy()\n",
    "    test_centers = centers.copy()\n",
    "    \n",
    "    nx, ny, ix = random_move(test_centers, weights)\n",
    "    old_x, old_y = test_centers[ix]\n",
    "    test_img[old_x-75: old_x+75, old_y-75:old_y+75] = 50\n",
    "    test_img[nx-75:nx+75, ny-75:ny+75] = 255\n",
    "    test_centers[ix] = (nx, ny)\n",
    "    \n",
    "    new_score, _ = evaluate(test_img, test_centers)\n",
    "    \n",
    "    return test_img, test_centers, new_score\n",
    "\n",
    "def random_move(centers, weights):\n",
    "    found_valid_move = False\n",
    "    newx, newy, random_index = 0, 0, 0\n",
    "    \n",
    "    while not found_valid_move:\n",
    "        cixs = list(range(len(centroids)))\n",
    "        random_index = np.random.choice(cixs, 1, p = weights)\n",
    "        #random_index = random.randint(0,len(centroids)-1)\n",
    "        \n",
    "        angle = np.pi * np.random.uniform(0, 2)\n",
    "        length = np.rint(perturb_len*decay_rate**iter)\n",
    "        dx, dy = length*np.cos(angle), length*np.sin(angle)\n",
    "        dx, dy = np.rint(dx), np.rint(dy)\n",
    "        newx, newy = int(centers[random_index][0] + dx), int(centers[random_index][1] + dy)\n",
    "\n",
    "        nbors = centers[:random_index] + centers[random_index+1:]\n",
    "        \n",
    "        found_valid_move = validate(newx, newy, nbors)\n",
    "    \n",
    "    return newx, newy, random_index\n",
    "\n",
    "def validate(cx, cy, centroids):   \n",
    "    cxbool = out_of_bounds_check(cx)\n",
    "    cybool = out_of_bounds_check(cy)\n",
    "    \n",
    "    rep = np.tile(np.array([cx, cy]).reshape(-1,2), [len(centroids), 1])\n",
    "    centroids_arr = np.array(centroids)\n",
    "    dist = np.sqrt(np.sum((rep-centroids_arr)**2, axis = 1))\n",
    "    min_dist = 2*(75*np.sqrt(2)+25)\n",
    "    valid = np.all(dist > min_dist)\n",
    "    \n",
    "    check = cxbool and cybool and valid\n",
    "    \n",
    "    return check\n",
    "\n",
    "def out_of_bounds_check(coord):\n",
    "    if (coord < 200) or (coord > window_size - 200):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def evaluate(im_pattern, centroids):\n",
    "    new_feats = []\n",
    "\n",
    "    for sigma in uniq_sigs:\n",
    "        feats = extract_features(im_pattern, sigma, centroids)\n",
    "        new_feats.append(feats[:, 0].reshape(-1,1))\n",
    "        new_feats.append(feats[:, 1].reshape(-1,1))\n",
    "\n",
    "    new_feats = [new_feats[ix] for ix in ix_sigs] \n",
    "    new_feats = np.hstack(new_feats)\n",
    "    preds = model.predict(new_feats)\n",
    "    #weights = rel_probs(preds)\n",
    "    pred_mean = np.mean(preds)\n",
    "    \n",
    "    # check if centroids IX matches weights IX\n",
    "    # should be the case as feats computes features \n",
    "    return pred_mean, preds\n",
    "\n",
    "def rel_probs(arr):\n",
    "    maxVal, minVal = np.max(arr), np.min(arr)\n",
    "    print(np.array(arr))\n",
    "    valSum = np.sum(arr)\n",
    "    weights = np.array([(maxVal - val + minVal)/valSum for val in arr])\n",
    "    return weights\n",
    "\n",
    "def backward_elim(X_iter, y, n_feats):\n",
    "    n_iter = X_iter.shape[1]\n",
    "    \n",
    "    while n_iter > n_feats:\n",
    "        feat_ix = list(range(X_iter.shape[1]))\n",
    "    \n",
    "        min_ix = 0\n",
    "        min_error = -np.infty\n",
    "        for ix in feat_ix:\n",
    "            cols = feat_ix[:ix] + feat_ix[ix+1:]\n",
    "            temp_df = X_iter.iloc[:, cols]\n",
    "            temp_error = cross_val_score(model, temp_df, y, cv = 5, scoring = \"neg_mean_squared_error\").mean()\n",
    "            if temp_error > min_error:\n",
    "                min_ix = ix\n",
    "                min_error = temp_error\n",
    "\n",
    "        cols = feat_ix[:min_ix] + feat_ix[min_ix+1:]\n",
    "        X_iter = X_iter.iloc[:, cols]\n",
    "        n_iter = X_iter.shape[1]\n",
    "        \n",
    "    return X_iter\n",
    "\n",
    "\n",
    "# configs\n",
    "curr_dir = os.path.abspath(os.getcwd())\n",
    "save_dir = os.path.join(curr_dir, \"modeling/disc_gen_outputs\")\n",
    "niter = 10\n",
    "perturb_len = 200\n",
    "decay_rate = 0.999\n",
    "epsilon = 0\n",
    "pattern_dim = 40\n",
    "p = 1/16\n",
    "pad = 200\n",
    "\n",
    "# args\n",
    "seeds = [7]\n",
    "cp.cuda.Device(int(0)).use()\n",
    "\n",
    "# train discriminator\n",
    "df = pd.read_csv(\"all_sigmas_df_comb.csv\")\n",
    "X, y = df.iloc[:, :-4], df.iloc[:, -1] \n",
    "model = SVR(kernel='rbf')\n",
    "X_reduc = backward_elim(X, y, 3)\n",
    "model = model.fit(X_reduc, y)\n",
    "\n",
    "# get features from backward elimination\n",
    "cols = X_reduc.columns.values\n",
    "print(cols)\n",
    "sigmas = [int(''.join(filter(str.isdigit, item))) for item in X_reduc.columns.values]\n",
    "uniq_sigs = sorted(list(set(sigmas)))\n",
    "f_density = lambda x: str(x) + \"_density\"\n",
    "f_grad = lambda x: str(x) + \"_grad\"\n",
    "all_feats = [f(sigma) for sigma in uniq_sigs for f in (f_density, f_grad)]\n",
    "ix_sigs = [all_feats.index(col) for col in cols]\n",
    "\n",
    "window_size = 0\n",
    "\n",
    "for seed in seeds:\n",
    "    # save initial image\n",
    "    im, centroids  = get_image(seed)\n",
    "    window_size = len(im)\n",
    "    im_init = Image.fromarray(im.astype(np.uint8))\n",
    "    im_init.save(os.path.join(save_dir,\"init_seed_\" + str(seed) + \".png\"))\n",
    "\n",
    "    log = []\n",
    "\n",
    "    curr_score, preds = evaluate(im, centroids)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "022a8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxVal, minVal = np.max(preds), np.min(preds)\n",
    "valSum = np.sum(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff2914aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5466337270278772, 0.09418305398231541, 14.578991376734399)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxVal, minVal, valSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8875c748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01025904, 0.01026288, 0.0102423 , 0.01023902, 0.01022245,\n",
       "       0.01007395, 0.01028783, 0.0101681 , 0.00947668, 0.00933553,\n",
       "       0.00997727, 0.01018115, 0.01026243, 0.00854921, 0.01015304,\n",
       "       0.00537437, 0.00839918, 0.00367558, 0.00864755, 0.01024259,\n",
       "       0.01029578, 0.00178693, 0.00190713, 0.00847195, 0.00988993,\n",
       "       0.00256467, 0.00402799, 0.00912371, 0.01024739, 0.0059922 ,\n",
       "       0.01011273, 0.01022917, 0.0101922 , 0.00987831, 0.01035105,\n",
       "       0.01006319, 0.00978323, 0.00857043, 0.00954962, 0.00974958,\n",
       "       0.01025973, 0.01013918, 0.01021773, 0.01016042, 0.01009448,\n",
       "       0.01035085, 0.01023594, 0.01024373, 0.01026107, 0.01026389,\n",
       "       0.01014491, 0.00877304, 0.00668087, 0.01026214, 0.00843247,\n",
       "       0.0102444 , 0.01026032, 0.01025338, 0.00959371, 0.00967636,\n",
       "       0.00962061, 0.01025676, 0.01004346, 0.01002406, 0.01026283,\n",
       "       0.01024731, 0.0102456 , 0.01030946, 0.01025629, 0.01025265,\n",
       "       0.00960141, 0.00955568, 0.01026078, 0.01011953, 0.01026024,\n",
       "       0.00998587, 0.01026526, 0.01025949, 0.01026807, 0.01026077,\n",
       "       0.01028046, 0.01021765, 0.01026039, 0.01023997, 0.00975842,\n",
       "       0.00970754, 0.01003727, 0.00905891, 0.01023412, 0.01024528,\n",
       "       0.0100564 , 0.00988188, 0.01024586, 0.01006922, 0.01034118,\n",
       "       0.01026112, 0.01024621, 0.01026458, 0.0102257 , 0.01004318,\n",
       "       0.00960986, 0.0100581 , 0.01037122, 0.01025726, 0.0103061 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phiArr = -1*preds+minVal+maxVal\n",
    "weights = phiArr / np.sum(phiArr)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69e61706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0,1,2], 1, p = [0.1,0.3,0.6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38782291",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c4f9645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.174618943088019"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(150/30)**(1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d79ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
